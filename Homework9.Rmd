---
title: "Homework9"
author: "Kavya Malgi"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      eval =TRUE, 
                      warning = FALSE,
                      message = FALSE,
                      include = TRUE,
                      fig.align = "center",
                      fig.show='hold',
                      R.options = list(max.print=50))


library(tibble)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(rvest)
library(sas7bdat)
library(knitr)
library(MatchIt)
library(boot)
library(broom)
```

github link: <https://github.com/kavyamalgi/Homework9>

## Problem 1: Manufacturing flaws in circuit boards

**Part A: Make two plots. The first plot should provide evidence that the size of the opening on the solder gun is related to the number of skips. The second should provide evidence that the thickness of the alloy used for soldering is related to the number of skips. Give each plot an informative caption describing what is shown in the plot.**

```{r}

solder <- read.csv("solder.csv")

ggplot(solder, aes(x = Opening, y = skips)) +
  geom_boxplot(fill = "lightblue") +
  labs (
    title = "Effect of Solder Gun Opening Size on # of Skips",
    x = "Opening Size",
    y = "# of Skips"
  )

ggplot(solder, aes(x = Solder, y = skips)) +
  geom_boxplot(fill = "darkblue") +
  labs(
    title = "Effect of Solder Thickness on # of Skips",
    x = "Solder Thickness",
    y = "# of Skips"
  )
```

Plot 1: The boxplot depicts the \# of solder skips that vary with the solder gun opening size. Boards that are manufactured with smaller openings have fewer skips on avg. meaning better quality.

Plot 2: The boxplot shows that the thinner a solder is, the less amount of skips there are compared to the thicker solder. This indicates taht solder thickness is a factor in the manufacturing quality.

------------------------------------------------------------------------

Part B: Build a regression model with skips as the outcome and with the following terms as predictors:\
• a main effect for Opening\
• a main effect for Solder type\
• an interaction between Opening and Solder type

Make a table that shows the estimate and 95% = large-sample confidence interval for each coefficient in your model.

```{r}
solder <- solder |>
  mutate (
    Opening = factor(Opening),
    Solder = factor(Solder)
  )

linear_model <- lm(skips ~ Opening * Solder, data = solder)

model_sum <- tidy(linear_model, conf.int = TRUE, conf.level = 0.95)

model_sum
```

------------------------------------------------------------------------

\newpage

**Part** **C: Interpret each estimated coefficient in your model in no more than 1-2 sentences. A good template here is provided in the course packet, when we fit a model for the video games data that had an interaction in it and interpreted each coefficient in a sentence or two**

```{r}
library(glue)

model_sum <- tidy(linear_model, conf.int = TRUE)

coefs <- setNames(model_sum$estimate, model_sum$term)

cat(glue("The baseline # of skips for curcuit boards that were manufactured with a large opening and thick solder is {round(coefs['(Intercept)'], 1)} skips. \n"))

cat(glue("The main effect for a medium opening is {round(coefs['Openingmedium'], 1)} skips. This shows the effect of a medium opening. \n"))

cat(glue("The main effect for a small opening is {round(coefs['Openingsmall'], 1)} skips. This shows the effect of a small opening. \n"))

cat(glue("The main effect for a thin solder is {round(coefs['Solderthin'], 1)} skips. This shows the effect of a thin solder in isolation \n"))

cat(glue("The interaction effect for medium opening and thin solder is {round(coefs['Openingmedium:Solderthin'], 1)} skips. \n"))

cat(glue("The interaction effect for small opening and thin solder is {round(coefs['Openingsmall:Solderthin'], 1)} skips. \n"))
```

------------------------------------------------------------------------

**Part D: If you had to recommend a combination of Opening size and Solder thickness to AT&T based on this analysis, which one would it be, and why? (Remember, the goal is to minimize the number of skips in the manufacturing process.)**

If I had to recommend a combination of Opening size and Solder thickness, based on the regression results, I would say that AT&T should use a small opening and a thin solder.

Using this combination would end up in the lowest predicted \# of skips, when discussing the individual effects of Opening size and Solder thickness for both.

The model showed that thinner solder reduces skips compared to thicker solder. Furthermore, small openings reduce skips compared to medium and large openings. Lastly, the interaction term for a small opening and thin solder doesn't change the benefit, and results in the combination to be more beneficial.

------------------------------------------------------------------------

## Problem 2: Grocery Store Prices

Part A. What kind of price differences do we see across the different stores? Make a bar graph with Store on the vertical axis and average price of products sold at that store on the horizontal axis. (Remember coord_flip.) Give your plot an informative caption. You’ll need to wrangle the data into an appropriate form first before you can make your plot.\

```{r}
grocery <- read.csv("groceries.csv")

avg_price <- grocery |>
  group_by(Store) |>
  summarize(avg = mean(Price, na.rm = TRUE)) |>
  arrange(desc(avg))

ggplot(avg_price, aes(x = reorder(Store, avg), y = avg)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Avg Product Price by Store",
    x = "Store",
    y = "Avg Price (USD)",
    caption = "The bar graph shows the avg. price for all products that were sold at each store."
    
  )
```

------------------------------------------------------------------------

**Part B: Please make a bar graph with Product on the vertical axis and number of stores selling that product on the horizontal axis. Give your bar graph an informative caption. Again, you’ll need to wrangle the data into an appropriate form first before you can make your plot. (For the purposes of this question, you can treat the two HEBs and two Whole Foods as separate stores, which makes the data wrangling easier. You’ll know you’ve gotten this right if your bar graph maxes out at 16 for eggs and milk.)**

```{r}

product <- grocery |>
  group_by(Product) |>
  summarize(stores = n_distinct(Store)) |>
  arrange(desc(stores))

ggplot(product, aes(x = reorder(Product, stores), y = stores )) +
  geom_col(fill = "lightblue") +
  coord_flip() +
  labs(
    title = "Product Availability Across Stores",
    x = "Product",
    y = "# of Stores Carrying Product",
    caption = "This shows how many of the 16 stores carry each product."
      
  )
```

------------------------------------------------------------------------

**Part C: Now let’s use regression to try to isolate the effects of Type of store versus the actual products being sold. Fit a model for Price versus Product and the Type of store. Fill in the blanks: “Compared with ordinary grocery stores (like Albertsons, HEB, or Krogers), convenience stores charge somewhere between (lower bound) and (upper bound) dollars more for the same product.” Use a large-sample confidence interval here, and round your answer to two decimal places, i.e. the nearest penny.**

```{r}



grocery <- grocery |>
  mutate(Type = relevel(factor(Type), ref = "Grocery"))

model_price <- lm(Price ~ Product + Type, data = grocery)

sum_model <- tidy(model_price, conf.int = TRUE)


# Now this should work
conf_int <- sum_model |>
  filter(term == "TypeConvenience ") |>
  select(conf.low, conf.high) |>
  mutate(
    conf.low = round(conf.low, 2),
    conf.high = round(conf.high, 2)
  )

conf_int


```

Compared with ordinary grocery stores (like Albertsons, H-E-B, or Kroger), convenience stores charge between \$0.41 and \$0.92 more for the same product, on average.

------------------------------------------------------------------------

Part D. Now fit a model for Price versus Product and Store. Which two stores seem to charge the lowest prices when comparing the same product? Which two stores seem to charge the highest prices when comparing the same product?

```{r}

grocery <- grocery |>
  mutate(Store = factor(Store))

store <- lm(Price ~ Product + Store, data = grocery)

summary_store <- tidy(store, conf.int = TRUE)

effect <- summary_store |>
  filter(grepl("^Store", term)) |>
  select(term, estimate, conf.low, conf.high)|>
  mutate(
    estimate = round(estimate, 2),
    conf.low = round(conf.low, 2),
    conf.high = round(conf.high, 2)
  ) |>
  arrange(estimate)

effect
```

After using the regression model comparing stores for the same product, the 2 stores with the lowest prices are Walmart (estimate = -0.99) and Kroger Fresh Fare (estimate = -0.90). The 2 stores that have the highest prices are Whole Foods (estimate = 0.36) and Wheatsville Food Co-Op (estimate = 0.29). The estimates are relative to the baseline store and describe the avg. difference in prices for the same product after accounting for differences across products, suggesting that the store choice has an important impact on price.

------------------------------------------------------------------------

**Part E. Central Market is owned by HEB but has a reputation as a fancier grocery store that charges premium prices. But is that because Central Market charges more for the same product? (This is referred to as price discrimination in the marketing world.) Or, on the other hand, is that because Central Market sells different products that are inherently more expensive than those sold at a typical HEB? Let’s use your model from Part D to try to disambiguate between two possibilities:\
• Central Market charges more than HEB for the same product.\
• Central Market charges a similar amount to HEB for the same product.\
Inspect the coefficients from your fitted model. Which of these two possibilities looks right to you? Cite specific numerical evidence from your model. Try to put any difference between HEB and Central Market into the larger context: how big is the HEB/Central Market difference, compared to differences among other stores?**

Referencing the regression model from Part D, we can compare the coeffs for HEB and Central Market.

-   HEB: -0.65

-   Central Market: -0.57

The coefficients above show the difference in price in relation to the baseline store. Central Market is only \$0.08 more expensive than HEB for the same products. The difference is small compared to the differences from other stores. It is safe to conclude that Central Market doesn't significantly charge more than HEB for the same product.

------------------------------------------------------------------------

**Part F. Finally let’s consider the Income variable. To facilitate interpretation, first use mutate to define an Income10K variable that measures income in multiples of \$10,000 (e.g. 1 = \$10,000, 2 = \$20,000, and so on). Then fit a model for Price versus Product and Income10K and use your model to answer these two questions:\
• Based on the sign of the Income10K coefficient, do consumers in poorer ZIP codes seem to pay more or less for the same product, on average? How do you know?\
• How large is the estimated size of the effect of Income10K on Price?**

```{r}
grocery <- grocery |>
  mutate(Income10K = Income / 10000)

model <- lm(Price ~ Product + Income10K, data = grocery)
summary(model)

standard <- grocery |>
  mutate(
    Price_s = scale(Price),
    Income10K_s = scale(Income10K)
  )

model <- lm(Price_s ~ Product + Income10K_s, data = standard)
summary(model)
```

After fitting a multiple regression model with Price as the outcome and Product and Income10K as predictors. Based on the sign of the Income10K coefficient, consumers in poorer ZIP codes may more if they have a negative coefficient and consumers in wealthier ZIP codes pay more for the same products if the coefficient is positive.

The coefficient on Income10K was negative (-0.014), indicating that consumers in poorer countries tend to pay more for the same product, on average. Although this is true, the relationship was not statistically significant(p=0.14) indicating that the evidence is weak that the income meaningfully affects price at all.

Furthermore, in order to interpret the size of this effect, I standardized both income and price and ran a second model using z-scores. The coefficient in this model for Income10K_s was -0.032, meaning that A one standard deviation increase in ZIP code income is associated with a 0.03 standard deviation decrease in product price. It is safe to say that income level may have only a minimal effect on the prices consumers pay for the same grocery products.

------------------------------------------------------------------------

## Problem 3: Redlining

A. ZIP codes with a higher percentage of minority residents tend to have more FAIR policies per 100 housing units. **TRUE**

-   Figure A1 shows a clear positive linear relationship and the regression table for model_A shows the coefficient for minority as 0.014 with a p-val \< 0.001, and the CI [0.009, 0.018] which doesn't include 0. It is safe to say that as % minority increases, FAIR policy rate increases.

B. The evidence suggests an interaction effect between minority percentage and the age of the housing stock in the way that these two variables are related to the number of FAIR policies in a ZIP code. **FALSE**

-   There is no interaction model between minority and housing age is given. The only possible model is model_C which is in regards to minority and fire risk.

C. The relationship between minority percentage and number of FAIR policies per 100 housing units is stronger in high-fire-risk ZIP codes than in low-fire-risk ZIP codes. **FALSE**

-   In Figure C1, the figure shows almost parallel slopes for high and low fire risk meaning that there might be similar strength of relationship. In model_C, the interaction term minority:fire_riskLow has a coeff of -0.001 with a p-val of 0.839 and a CI that does include 0.

D. Even without controlling for any other variables, income “explains away” all the association between minority percentage and FAIR policy uptake. **FALSE**

-   Referencing to model_D2, income is a control, and the coefficient for minority is still significant (0.01, p = 0.002), therefore the association between minority % and FAIR policies remains strong after controlling for income.

E. Minority percentage and number of FAIR policies are still associated at the ZIP code level, even after controlling for income, fire risk, and housing age. **TRUE**

-   Referencing model_E, the coefficient for minority is 0.008, with a p-val of 0.006, and a confidence interval - (0.003, 0.014) which doesn't include 0 and therefore shows a statistically significant association is there after a full adjustment.
